{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f191bae4-3f5b-4895-850a-6f2eba79c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load model and tokenizer once\n",
    "MODEL_PATH = r\"D:\\ChatBot\\phi1.5\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "# Function to generate AI response\n",
    "def generate_answer(question, model):\n",
    "    try:\n",
    "        prompt = (\n",
    "            \"You are a compassionate and informative AI health assistant.\\n\"\n",
    "            \"Answer the following health-related question clearly and supportively. Do not include any signature or names at the end:\\n\\n\"\n",
    "\n",
    "            f\"{question.strip()}\\n\\n\"\n",
    "            \"Answer:\"\n",
    "        )\n",
    "\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=400,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        # Debug: Show full model output\n",
    "        raw_output = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "        print(\"=== RAW MODEL OUTPUT ===\")\n",
    "        print(raw_output)\n",
    "        print(\"========================\")\n",
    "\n",
    "        # Get only the new tokens after the prompt\n",
    "        generated_ids = output_ids[0][len(input_ids[0]):]\n",
    "        answer = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        return answer.strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error: {str(e)}\"\n",
    "\n",
    "# Gradio interface wrapper\n",
    "def chatbot(question):\n",
    "    return generate_answer(question, llm_model)\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == '__main__':\n",
    "    interface = gr.Interface(\n",
    "        fn=chatbot,\n",
    "        inputs=gr.Textbox(\n",
    "            label=\"Your Question\",\n",
    "            placeholder=\"Ask a health-related question...\",\n",
    "            lines=4,\n",
    "        ),\n",
    "        outputs=gr.Textbox(\n",
    "            label=\"AI Health Assistant Response\",\n",
    "            lines=8,\n",
    "        ),\n",
    "        title=\"ü©∫ AI Health Assistant\",\n",
    "        description=(\n",
    "            \"Type any general health-related question below and receive helpful guidance from the AI assistant.\\n\"\n",
    "            \"‚ö†Ô∏è Note: This assistant is for informational purposes only and is **not** a substitute for professional medical advice.\"\n",
    "        ),\n",
    "        theme=\"soft\",\n",
    "        allow_flagging=\"never\",\n",
    "        live=True,  # enables typing-effect/streaming-like response\n",
    "    )\n",
    "    interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8f0d9-f215-4c16-becc-103f696686c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
